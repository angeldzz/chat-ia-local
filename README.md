

ğŸ¤– Chat IA Local
Una aplicaciÃ³n de chat moderna y elegante que se conecta a tu modelo de IA local


Conecta, conversa y explora el poder de la IA local con una interfaz futurista y elegante


âœ¨ CaracterÃ­sticas Principales



ğŸ–Œï¸ Interfaz Moderna
DiseÃ±o futurista con gradientes y glassmorphism


ğŸ“± Totalmente Responsive
Perfecto en desktop, tablet y mÃ³vil

System: 


ğŸ¤– Chat IA Local
Una aplicaciÃ³n de chat moderna y elegante que se conecta a tu modelo de IA local
![Vite](https://img shields.io/badge/Vite-5.x-646CFF?style=for-the-badge&logo=vite&logoColor=white)

Conecta, conversa y explora el poder de la IA local con una interfaz futurista y elegante


âœ¨ CaracterÃ­sticas Principales



ğŸ–Œï¸ Interfaz Moderna
DiseÃ±o futurista con gradientes y glassmorphism


ğŸ“± Totalmente Responsive
Perfecto en desktop, tablet y mÃ³vil


ğŸ’¬ Chat en Tiempo Real
Conversaciones fluidas y naturales




ğŸ§  Historial Inteligente
Mantiene el contexto de conversaciÃ³n


â³ Indicadores Visuales
Estados de carga y error elegantes


â™¿ Accesible
DiseÃ±o inclusivo y navegable




ğŸ› ï¸ Stack TecnolÃ³gico





TecnologÃ­a
VersiÃ³n
PropÃ³sito



âš›ï¸ React
18.x
Framework de UI


âš¡ Vite
5.x
Build tool ultra-rÃ¡pido


ğŸ¨ CSS3
-
Estilos modernos


ğŸ¤– LM Studio
0.3.16+
Servidor de IA local


ğŸ“¦ pnpm
8.x
Gestor de paquetes




ğŸš€ Inicio RÃ¡pido
ğŸ“‹ Requisitos Previos

âš ï¸ Importante: AsegÃºrate de tener todo instalado antes de continuar

# Verifica las versiones
node --version    # â‰¥ 16.0.0
pnpm --version    # â‰¥ 8.0.0


ğŸ’¾ InstalaciÃ³n de Dependencias


Node.js v16+ 
pnpm: npm install -g pnpm
LM Studio v0.3.16+



ğŸ”§ ConfiguraciÃ³n de LM Studio


graph TD
    A[ğŸ“¥ Descargar LM Studio] --> B[ğŸ¤– Descargar Modelo IA]
    B --> C[ğŸš€ Iniciar Servidor Local]
    C --> D[âœ… Verificar ConexiÃ³n]
    
    style A fill:#e1f5fe
    style B fill:#f3e5f5
    style C fill:#e8f5e8
    style D fill:#fff3e0







1ï¸âƒ£ Configurar LM Studio
# 1. Descargar LM Studio 0.3.16+
# 2. Instalar y abrir la aplicaciÃ³n




2ï¸âƒ£ Descargar Modelo
# Modelos recomendados:
# â€¢ Gemma 3 12B
# â€¢ Llama 3.1 8B
# â€¢ Phi 3 Medium






3ï¸âƒ£ Iniciar Servidor
# En LM Studio:
# Local Server â†’ Seleccionar modelo â†’ Start Server
# Servidor: http://localhost:1234




4ï¸âƒ£ Verificar API
# Endpoint disponible:
# http://localhost:1234/api/v1/chat/completions





ğŸ¯ InstalaciÃ³n del Proyecto
# 1ï¸âƒ£ Clonar el repositorio
git clone [URL_DEL_REPOSITORIO]
cd chat-ia-local

# 2ï¸âƒ£ Instalar dependencias
pnpm install

# 3ï¸âƒ£ Ejecutar en desarrollo
pnpm dev

# 4ï¸âƒ£ Abrir en el navegador
# ğŸŒ http://localhost:5173



ğŸ‰ Â¡Listo! Tu chat IA local estÃ¡ funcionando


ğŸ“ Arquitectura del Proyecto
ğŸ“¦ chat-ia-local/
â”œâ”€â”€ ğŸ“‚ src/
â”‚   â”œâ”€â”€ ğŸ¨ App.jsx          # Componente principal del chat
â”‚   â”œâ”€â”€ ğŸ’„ App.css          # Estilos principales
â”‚   â”œâ”€â”€ ğŸŒ index.css        # Estilos globales
â”‚   â””â”€â”€ ğŸš€ main.jsx         # Punto de entrada
â”œâ”€â”€ ğŸ“‚ public/              # Archivos estÃ¡ticos
â”œâ”€â”€ ğŸ“„ package.json         # ConfiguraciÃ³n del proyecto
â”œâ”€â”€ ğŸ“– README.md           # Esta documentaciÃ³n
â””â”€â”€ âš™ï¸ vite.config.js       # ConfiguraciÃ³n de Vite

ğŸ¨ PersonalizaciÃ³n Avanzada
ğŸ¤– Cambiar Modelo de IA
// En App.jsx
const modeloIA = "gemma-3-12b-instruct"; // ğŸ‘ˆ Cambia aquÃ­

ğŸ­ Personalizar Estilos

Ver opciones de personalizaciÃ³n

/* En App.css - Variables CSS personalizables */
:root {
  --primary-color: #6366f1;     /* Color principal */
  --secondary-color: #8b5cf6;   /* Color secundario */
  --accent-color: #06b6d4;      /* Color de acento */
  --background-dark: #0f172a;   /* Fondo oscuro */
  --glass-bg: rgba(255, 255, 255, 0.1); /* Efecto glass */
}



âš™ï¸ Configurar Temperatura
// Ajustar creatividad de la IA
const data = {
  "model": modeloIA,
  "messages": mensajesParaAPI,
  "temperature": 0.8,  // 0.1 (conservador) - 1.0 (creativo)
  "max_tokens": 1000   // LÃ­mite de tokens
};

ğŸ”§ Scripts Disponibles





Comando
DescripciÃ³n
Uso



pnpm dev
ğŸš€ Desarrollo
Servidor local con hot-reload


pnpm build
ğŸ“¦ ProducciÃ³n
Build optimizado


pnpm preview
ğŸ‘€ Vista previa
Preview del build


pnpm lint
ğŸ” Linting
Verificar cÃ³digo




ğŸ› SoluciÃ³n de Problemas

ğŸ”Œ Error de ConexiÃ³n

# Verificaciones:
âœ… LM Studio estÃ¡ ejecutÃ¡ndose
âœ… Servidor local activo (puerto 1234)
âœ… Modelo cargado correctamente
âœ… Firewall no bloquea el puerto




ğŸ¤– Modelo No Responde

# Posibles soluciones:
âœ… Verificar modelo cargado en LM Studio
âœ… Confirmar nombre del modelo correcto
âœ… Esperar a que el modelo se cargue completamente
âœ… Reiniciar LM Studio si es necesario




âš¡ Problemas de Rendimiento

# Optimizaciones:
âœ… Usar modelo mÃ¡s pequeÃ±o (< 8GB RAM)
âœ… Ajustar configuraciÃ³n de LM Studio
âœ… Reducir temperatura para respuestas mÃ¡s rÃ¡pidas
âœ… Cerrar otras aplicaciones pesadas



ğŸ“Š Compatibilidad





Sistema Operativo
Navegador
Estado



ğŸªŸ Windows 10/11
Chrome 90+
âœ… Compatible


ğŸ macOS 10.15+
Safari 14+
âœ… Compatible


ğŸ§ Linux Ubuntu
Firefox 88+
âœ… Compatible


ğŸ“± iOS 14+
Safari Mobile
âœ… Compatible


ğŸ¤– Android 8+
Chrome Mobile
âœ… Compatible




ğŸ¤ Contribuir


Â¡Contribuciones bienvenidas! ğŸ‰


# 1ï¸âƒ£ Fork el proyecto
# 2ï¸âƒ£ Crea tu rama de feature
git checkout -b feature/AmazingFeature

# 3ï¸âƒ£ Commit tus cambios
git commit -m 'Add some AmazingFeature'

# 4ï¸âƒ£ Push a la rama
git push origin feature/AmazingFeature

# 5ï¸âƒ£ Abre un Pull Request

ğŸ“„ Licencia


Este proyecto estÃ¡ bajo la Licencia MIT - ve el archivo LICENSE para mÃ¡s detalles.

â­ Si te gusta este proyecto, Â¡dale una estrella!
